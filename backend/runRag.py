#!/usr/bin/env python3
"""
runRag.py â€” Dental RAG entry-point (OpenAI v0.x / v1.x ä¸¡å¯¾å¿œç‰ˆ)
==============================================================
1. å—ã‘å–ã£ãŸè³ªå•ã‚’ `ragPromptBuilder.build_prompt()` ã§ RAG ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŒ–ã€‚
2. OpenAI API ã¸é€ä¿¡ã—å›ç­”ã‚’å–å¾—ï¼ˆv0.xãƒ»v1.x è‡ªå‹•åˆ¤åˆ¥ï¼‰ã€‚
3. `--debug` ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ & æ¤œç´¢ãƒãƒ£ãƒ³ã‚¯ã‚’ JSON è¡¨ç¤ºã€‚

Usage
-----
```bash
$ python runRag.py "æ ¹å°–ç—…å¤‰ã®æ²»ç™‚ã¯ï¼Ÿ"
$ python runRag.py "ç¡çœ æ™‚ç„¡å‘¼å¸ç—‡å€™ç¾¤ã¨ã¯" --top_k 2 --debug
```
"""
from __future__ import annotations

import argparse
import json
import os
import sys
from typing import List, Dict, Any, Callable

# --------------------------------------------------------------------------- #
# OpenAI version-agnostic import helper
# --------------------------------------------------------------------------- #
try:
    # v1.x ç³» (openai>=1.0.0)
    from openai import OpenAI  # type: ignore

    _client = OpenAI()

    def _chat_completion_v1(
        messages: List[Dict[str, str]], *, model: str, temperature: float, timeout: int
    ) -> str:
        resp = _client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            timeout=timeout,
        )
        return resp.choices[0].message.content.strip()

    _call_chat: Callable[..., str] = _chat_completion_v1

except ImportError:
    try:
        # v0.x ç³» (openai<=0.28)
        import openai  # type: ignore

        def _chat_completion_v0(
            messages: List[Dict[str, str]], *, model: str, temperature: float, timeout: int
        ) -> str:
            resp = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                temperature=temperature,
                request_timeout=timeout,
            )
            return resp.choices[0].message["content"].strip()  # type: ignore[index]

        _call_chat = _chat_completion_v0  # type: ignore[assignment]

    except ImportError:
        sys.stderr.write(
            "âŒ openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n    `pip install openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n"
        )
        sys.exit(1)

# --------------------------------------------------------------------------- #
from ragPromptBuilder import build_prompt  # åŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ³å®š

# --------------------------------------------------------------------------- #
# ğŸ”´ä¸‹è¨˜ã‹ã‚‰ã®ã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã§ããªã„
# --------------------------------------------------------------------------- #
MODEL = "gpt-4.1-nano"
TEMPERATURE = 0.1
TIMEOUT = 30  # ç§’
MAX_RETRIES = 1

# --------------------------------------------------------------------------- #
# Utility: RAG ã‚’å‘¼ã³å‡ºã™é–¢æ•°
# --------------------------------------------------------------------------- #
def ask_rag(question: str, top_k: int = 3) -> str:
    """
    è³ªå•æ–‡å­—åˆ—ã‚’å—ã‘å–ã‚Šã€RAG ã®å›ç­”ã‚’è¿”ã™ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã€‚
    FastAPI ã‹ã‚‰ã¯ã“ã¡ã‚‰ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚
    """
    # 1) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒãƒ£ãƒ³ã‚¯ã®å–å¾—
    pkg = build_prompt(question, top_k=top_k)
    messages = pkg["messages"]

    # 2) GPT å‘¼ã³å‡ºã—ï¼ˆãƒªãƒˆãƒ©ã‚¤ãªã—ï¼‰
    answer = _call_chat(
        messages,
        model=MODEL,
        temperature=TEMPERATURE,
        timeout=TIMEOUT,
    )
    return answer

# --------------------------------------------------------------------------- #
# CLI entry point
# --------------------------------------------------------------------------- #

def main() -> None:
    parser = argparse.ArgumentParser(description="Dental RAG â€” run with GPT-4o-nano")
    parser.add_argument(
        "question", nargs="*", help="è³ªå•æ–‡ã‚’ç›´æ¥æŒ‡å®š (è¤‡æ•°èªå¯)"
    )
    parser.add_argument(
        "--top_k", type=int, default=3, help="retrieval chunk æ•° (default: 3)"
    )
    parser.add_argument(
        "--debug", action="store_true", help="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒãƒ£ãƒ³ã‚¯ã‚’è¡¨ç¤º"
    )
    args = parser.parse_args()

    # 1) è³ªå•å–å¾—
    if args.question:
        question = " ".join(args.question)
    else:
        question = input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()

    if not question:
        print("è³ªå•ãŒç©ºã§ã™ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        sys.exit(0)

    # 2) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    pkg: Dict[str, Any] = build_prompt(question, top_k=args.top_k)
    messages: List[Dict[str, str]] = pkg["messages"]

    if args.debug:
        print("\n----- Retrieval Chunks -----")
        print(json.dumps(pkg["chunks"], ensure_ascii=False, indent=2))
        print("\n----- Prompt (messages) -----")
        print(json.dumps(messages, ensure_ascii=False, indent=2))
        print("----------------------------\n")

    # 3) GPT å‘¼ã³å‡ºã—ï¼ˆç°¡æ˜“ãƒªãƒˆãƒ©ã‚¤ï¼‰
    last_error: Exception | None = None
    for attempt in range(MAX_RETRIES + 1):
        try:
            answer = _call_chat(
                messages,
                model=MODEL,
                temperature=TEMPERATURE,
                timeout=TIMEOUT,
            )
            break
        except Exception as e:  # pylint: disable=broad-except
            last_error = e
            sys.stderr.write(
                f"âš ï¸  API error, retrying ({attempt + 1}/{MAX_RETRIES})â€¦\n    {e}\n"
            )
    else:
        sys.stderr.write(f"âŒ OpenAI API å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ:\n{last_error}\n")
        sys.exit(1)

    # 4) å‡ºåŠ›
    print("\n=== å›ç­” ===")
    print(answer)


if __name__ == "__main__":
    if os.getenv("OPENAI_API_KEY") is None:
        sys.stderr.write(
            "âŒ OPENAI_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
        )
        sys.exit(1)
    main()
